{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eRteSKZ5VKai"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0012e54ff7fa4746ba4e49b58c1acb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5979ab133a73480399bea84f44ff93c6",
              "IPY_MODEL_114269cd7d6e4ca591e940ae5cee3352",
              "IPY_MODEL_85595421b8284c61a6f16ec76a0cf156"
            ],
            "layout": "IPY_MODEL_7c8ab5da0dad49abb5b61cbf5b254ef6"
          }
        },
        "5979ab133a73480399bea84f44ff93c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84781f0a676a4248991412e0bd149eee",
            "placeholder": "​",
            "style": "IPY_MODEL_5887a61716cc428a93fc71b8f52f50e3",
            "value": "100%"
          }
        },
        "114269cd7d6e4ca591e940ae5cee3352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_776da32ceb5941649818b8b83d4b5973",
            "max": 10306551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e241044b6d724a01a9c4195cf6cd65f0",
            "value": 10306551
          }
        },
        "85595421b8284c61a6f16ec76a0cf156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2def93330d1e4ef082974a473acfbc70",
            "placeholder": "​",
            "style": "IPY_MODEL_f142769865064a8fad356caaf40e0023",
            "value": " 9.83M/9.83M [00:00&lt;00:00, 116MB/s]"
          }
        },
        "7c8ab5da0dad49abb5b61cbf5b254ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84781f0a676a4248991412e0bd149eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5887a61716cc428a93fc71b8f52f50e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "776da32ceb5941649818b8b83d4b5973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e241044b6d724a01a9c4195cf6cd65f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2def93330d1e4ef082974a473acfbc70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f142769865064a8fad356caaf40e0023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arsenii-Girchenko/Colab/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22%D0%91%D0%B0%D0%B7%D0%BE%D0%B2%D0%BE%D0%B5_%D0%94%D0%97_FlowerClassification_ipynb%22%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJHy7vziiPnC"
      },
      "source": [
        "# ДЗ. Классификация цветов\n",
        "\n",
        "### Продолжим работать с [Датасетом](https://www.kaggle.com/alxmamaev/flowers-recognition ) для классификации цветов (тюльпан, ромашка, подсолнух, роза, одуванчик).\n",
        "\n",
        "\n",
        "### Загрузите папку с картинками на свой гугл-диск, и подключите диск к коллабу."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAgI8TKa0AqD",
        "outputId": "565a4b0b-42f1-4503-c301-50706aeafbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRteSKZ5VKai"
      },
      "source": [
        "# Подготовка датасета и функции для обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXtAgtr2V3u6"
      },
      "source": [
        "Загружаем библиотеки. Фиксируем random.seed для воспроизводимости"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvM84NDjxCnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8151e5bb-5b1e-4859-8017-fef75ac0116b"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbb232e8470>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjYDp6nXWWmQ"
      },
      "source": [
        "Выбираем на чем будем делать вычисления - CPU или GPU (cuda)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzyQGtNfzMsI",
        "outputId": "a660f4cf-3da5-47dc-8183-bc9d5132f9e2"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV-txOlLyJhK"
      },
      "source": [
        "prepare_imgs = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.Resize((224, 224)), #приводим картинки к одному размеру\n",
        "        torchvision.transforms.ToTensor(), # упаковывем их в тензор\n",
        "        torchvision.transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] # нормализуем картинки по каналам\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "# задаем датасет. Лейблы - имена папок: \n",
        "dataset = ImageFolder('/content/gdrive/MyDrive/Flowers/Flower_recognition/flowers', transform=prepare_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcuefCcB8iwi",
        "outputId": "9b00d147-a073-4dcd-f0d6-dcc17a5adaff"
      },
      "source": [
        "dataset.imgs[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gdrive/MyDrive/Flowers/Flower_recognition/flowers/daisy/10172379554_b296050f82_n.jpg',\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_DuonGn5HVb"
      },
      "source": [
        "class ValueMeter(object):\n",
        "  \"\"\"\n",
        "  Вспомогательный класс, чтобы отслеживать loss и метрику\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "      self.sum = 0\n",
        "      self.total = 0\n",
        "\n",
        "  def add(self, value, n):\n",
        "      self.sum += value*n\n",
        "      self.total += n\n",
        "\n",
        "  def value(self):\n",
        "      return self.sum/self.total\n",
        "\n",
        "def log(mode, epoch, loss_meter, accuracy_meter, best_perf=None):\n",
        "  \"\"\"\n",
        "  Вспомогательная функция, чтобы \n",
        "  \"\"\"\n",
        "  print(\n",
        "      f\"[{mode}] Epoch: {epoch:0.2f}. \"\n",
        "      f\"Loss: {loss_meter.value():.2f}. \"\n",
        "      f\"Accuracy: {100*accuracy_meter.value():.2f}% \", end=\"\\n\")\n",
        "\n",
        "  if best_perf:\n",
        "      print(f\"[best: {best_perf:0.2f}]%\", end=\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP0M3cL8ZDd3"
      },
      "source": [
        "### Задаем параметры и функцию для обучения. Разбиваем датасет на train/validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwhX2vdquink"
      },
      "source": [
        "batch_size = 32 # размер батча\n",
        "lr = 0.001 # learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG0zjMWDYu32"
      },
      "source": [
        "Разбиваем датасет на train и validation\n",
        "\n",
        "Задаем dataloader'ы - объекты для итеративной загрузки данных и лейблов для обучения и валидации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2AW1YTupITs",
        "outputId": "d6729c84-911c-44e8-f90a-654bb7e3f96f"
      },
      "source": [
        "train_set, val_set = torch.utils.data.random_split(dataset, [len(dataset)-1000, 1000])\n",
        "print('Размер обучающего и валидационного датасета: ', len(train_set), len(val_set))\n",
        "loaders = {'training': DataLoader(train_set, batch_size, pin_memory=True,num_workers=2, shuffle=True),\n",
        "           'validation':DataLoader(val_set, batch_size, pin_memory=True,num_workers=2, shuffle=False)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер обучающего и валидационного датасета:  3317 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuiJKWrYZZgb"
      },
      "source": [
        "Функция для подсчета Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm15u4TsDcIY"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzW60Io-riGV"
      },
      "source": [
        "Функция для обучения и валидации модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdlXyjEGhU4W"
      },
      "source": [
        "def trainval(model, loaders, optimizer, epochs=10):\n",
        "    \"\"\"\n",
        "    model: модель, которую собираемся обучать\n",
        "    loaders: dict с dataloader'ами для обучения и валидации\n",
        "    optimizer: оптимизатор\n",
        "    epochs: число обучающих эпох (сколько раз пройдемся по всему датасету)\n",
        "    \"\"\"\n",
        "    loss_meter = {'training': ValueMeter(), 'validation': ValueMeter()}\n",
        "    accuracy_meter = {'training': ValueMeter(), 'validation': ValueMeter()}\n",
        "\n",
        "    loss_track = {'training': [], 'validation': []}\n",
        "    accuracy_track = {'training': [], 'validation': []}\n",
        "\n",
        "    for epoch in range(epochs): # итерации по эпохам\n",
        "        for mode in ['training', 'validation']: # обучение - валидация\n",
        "            # считаем градиаент только при обучении:\n",
        "            with torch.set_grad_enabled(mode == 'training'):\n",
        "                # в зависимоти от фазы переводим модель в нужный ружим:\n",
        "                model.train() if mode == 'training' else model.eval()\n",
        "                for imgs, labels in tqdm(loaders[mode]):\n",
        "                    imgs = imgs.to(device) # отправляем тензор на GPU\n",
        "                    labels = labels.to(device) \n",
        "                    bs = labels.shape[0]  # размер батча (отличается для последнего батча в лоадере)\n",
        "\n",
        "                    preds = model(imgs) # forward pass - прогоняем тензор с картинками через модель\n",
        "                    loss = F.cross_entropy(preds, labels) # считаем функцию потерь\n",
        "                    acc = accuracy(preds, labels) # считаем метрику\n",
        "\n",
        "                    # храним loss и accuracy для батча\n",
        "                    loss_meter[mode].add(loss.item(), bs)\n",
        "                    accuracy_meter[mode].add(acc, bs)\n",
        "\n",
        "                    # если мы в фазе обучения\n",
        "                    if mode == 'training':\n",
        "                        optimizer.zero_grad() # обнуляем прошлый градиент\n",
        "                        loss.backward() # делаем backward pass (считаем градиент)\n",
        "                        optimizer.step() # обновляем веса\n",
        "            # в конце фазы выводим значения loss и accuracy\n",
        "            log(mode, epoch, loss_meter[mode], accuracy_meter[mode])\n",
        "\n",
        "            # сохраняем результаты по всем эпохам\n",
        "            loss_track[mode].append(loss_meter[mode].value())\n",
        "            accuracy_track[mode].append(accuracy_meter[mode].value())\n",
        "    return loss_track, accuracy_track             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJFCbGkObf_4"
      },
      "source": [
        "def set_parameter_requires_grad(model):\n",
        "  \"\"\"\n",
        "  Функция для заморозки весов модели\n",
        "  \"\"\"\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rtKZrQF0oma"
      },
      "source": [
        "# Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27qiLUtR011m"
      },
      "source": [
        "В домашнем задании попробуем обучить еще одну сверточную архитектуру.\n",
        "\n",
        "1) Разберите более детально код выше (или код с практики, они идентичны). Запустите весь код в этом ноутбуке.\n",
        "\n",
        "\n",
        "2) Посмотрите как задаются [модели сверточных сетей в PyTorch](https://pytorch.org/vision/stable/models.html), выберите одну модель из списка:\n",
        "\n",
        "*   alexnet\n",
        "*   vgg16\n",
        "*   mobilenet_v2\n",
        "*   mobilenet_v3_small\n",
        "*   densenet\n",
        "\n",
        "3) Дообучите выбранную модель для задачи классификации цветов, по аналогии с тем, как мы дообучали resnet18 на занятии. Чтобы это сделать замените ____ в ячейках ниже на код. Где-то надо вставить нужную переменную, где-то прописать константу. Главное не пугайтесь! Аналогичный код можно найти в ноутбуке с практикой ;)\n",
        "\n",
        "4) Если вам интересно, прочитайте дополнительно про эти архитектуры. Можно почитать [здесь (на английском)](https://medium.com/@fransiska26/the-differences-between-inception-resnet-and-mobilenet-e97736a709b0) или [здесь (на русском)](https://habr.com/ru/company/nix/blog/430524/)\n",
        "\n",
        "**Совет 1:** загрузите папку с картинками на гугл диск, чтобы не загружать ее каждый раз заново при перезапуске колаба. Структура файлов (можно посмотреть в меню слева) должна быть такой: drive/MyDrive/flowers\n",
        "\n",
        "**Совет 2:** обязательно подключите аппаратный ускоритель (GPU) к среде выполнения, чтобы вычисления были. В меню сверху: Среда выполнения -> Сменить среду выполнения\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZGKQ77DqT31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0012e54ff7fa4746ba4e49b58c1acb8f",
            "5979ab133a73480399bea84f44ff93c6",
            "114269cd7d6e4ca591e940ae5cee3352",
            "85595421b8284c61a6f16ec76a0cf156",
            "7c8ab5da0dad49abb5b61cbf5b254ef6",
            "84781f0a676a4248991412e0bd149eee",
            "5887a61716cc428a93fc71b8f52f50e3",
            "776da32ceb5941649818b8b83d4b5973",
            "e241044b6d724a01a9c4195cf6cd65f0",
            "2def93330d1e4ef082974a473acfbc70",
            "f142769865064a8fad356caaf40e0023"
          ]
        },
        "outputId": "010e54cc-976c-4d00-c976-9160a4ab1a88"
      },
      "source": [
        "# Выберите модель из списка доступных в PyTorch моделей\n",
        "# Не забудьте указать, что она модель должна быть предобучена!\n",
        "model = torchvision.models.mobilenet_v3_small(pretrained=True)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/9.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0012e54ff7fa4746ba4e49b58c1acb8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV3(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "      (2): Hardswish()\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
              "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
              "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
              "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (12): Conv2dNormActivation(\n",
              "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "      (2): Hardswish()\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
              "    (1): Hardswish()\n",
              "    (2): Dropout(p=0.2, inplace=True)\n",
              "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVgqf7x4aOo"
      },
      "source": [
        "set_parameter_requires_grad(model) # передайте модель в функцию для \"заморозки\" градиента"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXqwU5Rd5DYs"
      },
      "source": [
        "model.classifier = nn.Linear(576,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaquxdRWJ_LK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c23c45f-5318-4eb4-8db2-c38bd203e0f2"
      },
      "source": [
        "# Проверим все ли сработало правильно, выведем веса, которые будут обучаться\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTE0EUG9lh5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87b49e1-596d-4d7a-e509-497abbcce9d5"
      },
      "source": [
        "model.to(device) # Отправляем модель на GPU\n",
        "optimizer = torch.optim.Adam(params = model.parameters()) # алгоритм оптимизации\n",
        "loss_track, accuracy_track = trainval(model, loaders, optimizer, epochs=5) # запускаем обучение, задаем количество эпох"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [09:22<00:00,  5.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[training] Epoch: 0.00. Loss: 0.93. Accuracy: 71.00% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [03:11<00:00,  5.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[validation] Epoch: 0.00. Loss: 0.58. Accuracy: 82.10% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [00:15<00:00,  6.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[training] Epoch: 1.00. Loss: 0.75. Accuracy: 76.53% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[validation] Epoch: 1.00. Loss: 0.53. Accuracy: 82.85% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [00:15<00:00,  6.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[training] Epoch: 2.00. Loss: 0.67. Accuracy: 79.24% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[validation] Epoch: 2.00. Loss: 0.50. Accuracy: 83.80% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [00:15<00:00,  6.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[training] Epoch: 3.00. Loss: 0.61. Accuracy: 80.76% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[validation] Epoch: 3.00. Loss: 0.48. Accuracy: 84.45% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [00:15<00:00,  6.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[training] Epoch: 4.00. Loss: 0.57. Accuracy: 81.75% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:04<00:00,  6.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[validation] Epoch: 4.00. Loss: 0.47. Accuracy: 84.84% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(accuracy_track['training'], label='training')\n",
        "plt.plot(accuracy_track['validation'], label='validation')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.grid()\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "AeyhOaqu-zOn",
        "outputId": "6965eaa3-cdb8-4f5d-8560-3f34533a9852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbb10400610>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8deHrGQlCwkBAgmLEJA9bFI1KN6LtVVrURBFsSJdXKpt79Xe21q17e96+/CqtVqrImhVRGq1Uosi1MSlAgYEEcK+CIEAYSeB7J/fH+ckTMIEJpDJTJLP8/GYBzNzvmfmndE5n/me7znfI6qKMcYY01CHQAcwxhgTnKxAGGOM8coKhDHGGK+sQBhjjPHKCoQxxhivQgMdoLkkJydrRkbGOa9fWlpKdHR08wVqJparaSxX01iupmmLuVauXHlAVTt7XaiqbeI2YsQIPR+5ubnntb6/WK6msVxNY7mapi3mAlZoI9tV28VkjDHGKysQxhhjvLICYYwxxqs2M0jtTWVlJYWFhZSVlZ21bXx8POvXr2+BVE0TbLkiIyPp3r17oGMYY1pAmy4QhYWFxMbGkpGRgYicse3x48eJjY1toWS+C6ZcqsrBgwcpLCwMdBRjTAto07uYysrKSEpKOmtxML4REZKSknzqkRljWr82XSAAKw7NzD5PY9qPNr2LyRhj2ozKMjh5CE4ccv49ebjuftqeA0BOs7+lFQg/O3LkCHPnzuVHP/pRk9b75je/ydy5cwkJCWm0zYMPPsgll1zChAkTzjemMaalVFdB2RF343640Y2+8++RU/erTjb6kl3i+vklqhUIPzty5Ah//OMfTysQVVVVhIY2/vEvXLgQcAapG/PII480T0hjTNOpQvmxBhv1w2fe6J88DGVHG39NCYGOCRCVCB0ToVM6pA32eC7Beb52ufv8qn8t90P/wQqE3z3wwANs3bqVoUOHEhYWRmRkJAkJCWzYsIFNmzZx7bXXsmvXLsrKyvjxj3/MzJkzAcjIyGDFihXs3buX66+/nm984xt89tlndOvWjXfeeYeOHTsyffp0vvWtbzFp0iQyMjK49dZb+fvf/05lZSV/+ctf6N+/P8XFxUydOpU9e/YwduxYFi9ezMqVK0lOTg7wJ2NMEDnD7hvnvrPRH1a0HdbWnHq+pqrx14yIh6iEUxvypN71NurOhj6h/kY/Ig6CaJyv3RSIh/++joI9xxpdXl1dfcbdOd4M6BrHr7498IxtHn30UdauXcvq1avJy8vjqquuYu3atWRmZgIwe/ZsEhMTOXnyJCNHjuS73/0uSUlJ9V5j8+bNvP7667zwwgvccMMN/PWvf+Xmm28+7b2Sk5P54osv+OMf/8hjjz3GrFmzePjhh7nsssv4+c9/zvvvv8+LL77YpL/RmFal0d033n7VH/Zp9w2hHet+vdd0CIWUXqdv6Ott9BMhshOEtP7Na+v/C1qZUaNG1RUHgKeeeoq3334bgF27drF58+bTCkRmZiZDhw4FYMSIEezYscPra1933XV1bd566y0APv3007rXnzhxIgkJCc369xjjF6pQdqzBRv1Ig/3zXjb6fth9Q1jHupf4Mi+PnJwc///9QaLdFIiz/dJvqRPSPKfkzcvLY8mSJSxdupSoqChycnK8nmMQERFRdz8kJISTJ73/2qltFxISQlXVGbq+xgRaxQk4uguO7IIjX5+67/57Sck++Ki68fXbwO6b1qDdFIhAiY2NbXSg+ejRoyQkJBAVFcWGDRtYtmxZs7//uHHjmD9/Pvfffz8ffPABhw8fbvb3MOY0J4+4G/udHhv+naf+PXGwfvsOoRDfHeLTofd4dh0qp2f/oW16901rYJ+ynyUlJTFu3DguvPBCOnbsSGpqat2yiRMn8qc//YmsrCz69evHmDFjmv39f/WrX3HjjTfyyiuvMHbsWLp06RI0U3eYVkoVSg+4G/yd9X751xWB8gbjfaEdnV068emQNgQ69YD4Hqeei+0CHU6NAW7Py6PnRTkt+3eZ01iBaAFz5871+nxERATvvfee12W14wwRERGsXbu27vmf/exndfdfeuml09oDZGdnk5eXBziT/S1atIjQ0FCWLl1Kfn5+vV1WxpymphqOF3n/5X9kFxwtPH1QNyLe2dh36gEZ49wCkO4WgB4QnWy7d1ohvxYIEZkI/B4IAWap6qMNlvcAXgY6uW0eUNWFDZYXAA+p6mP+zNpW7dy5kxtuuIGamhrCw8N54YUXAh3JBFpVBRwrhCO76FK0BHKX1i8Cx3affvhmVLKzsU/Jggv+vUEBSIeOnQLztxi/8luBEJEQ4BngCqAQyBeRBapa4NHsF8B8VX1WRAYAC4EMj+WPA95/Yhuf9O3bl1WrVgU6hmlJngPAR3c2GAfY5fQOUAD6A2wUiE1zNvbpo+r/8u+U7owNhAffdZiN//mzBzEK2KKq2wBEZB5wDU6PoJYCce79eGBP7QIRuRbYDpT6MaMxrU/dAHCD3T9nGgCO6+b86u89vt4v/2UbixhzxXUQGh6Yv8UENXGuWe2HFxaZBExU1Rnu42nAaFW9y6NNGvABkABEAxNUdaWIxACLcXofPwNKvO1iEpGZwEyA1NTUEfPmzau3PD4+nj59+viU91xOlGsJwZhry5Yt7N69m5iYmEBHOU1JSUnrzqVKWOVRIsuKiSzbT2TZfiLKT92PLCsmtPpEvVWqO4RTHtGZssgU99bZvaVSHtGZ8ogE5xyA88nVwixX05xPrvHjx69U1WxvywI9SH0j8JKq/p+IjAVeEZELgYeAJ1S15EzTS6vq88DzANnZ2drwBJb169f7fMROMF2Yx1Mw5oqMjCQmJiYoTxjKC9ITmepy1VTD8b3ef/k3OgAc5/z67zbg1D7/Tj3qdgOFRCcTJULU+eQKMparafyVy58FYjeQ7vG4u/ucp9uBiQCqulREIoFkYDQwSUR+hzOAXSMiZar6tB/zGtN8ThyCfWthXwHsX8eQbV/A6uO+DQDXKwA2AGwCx58FIh/oKyKZOIVhCjC1QZudwOXASyKSBUQCxap6cW0DEXkIZxdTuygOMTExlJSUsGfPHu655x7mzJlzWpucnBwee+wxsrO99goBePLJJ5k5cyZRUc7vytrpwzt1so1Ns6oqhwObnEKwby3sWwf7C9yBYFdUEh1CO0OPkdDpugbnANgAsAlefisQqlolIncBi3AOYZ2tqutE5BFghaouAH4KvCAi9+EMWE9Xfw2KtDJdu3blzTffPON032fy5JNPcvPNN9cViNrpw805UnV+/TcsBAc2neoRhIRD537QKwdSBkDqQEi9EGJSWPXRR0G5a8KYM/HrGIR7TsPCBs896HG/ABh3ltd4yC/hWsgDDzxAeno6d955JwAPPfQQoaGh5ObmcvjwYSorK/nNb37DNddcU2+9HTt28K1vfYulS5dy8uRJbrvtNr788kv69+9fby6mH/7wh+Tn53Py5EkmTZrEww8/zFNPPcWePXsYP348ycnJ5Obm1k0fnpyczOOPP87s2bMBmDFjBvfeey87duzgyiuv9DqteLtTXgL719cvBPvW1p8ILj7dKQD9rnSLwYXOfEAhYYHLbUwzC/Qgdct57wHY+1WjiztWVzV9fpcug+DKR8/YZPLkydx77711BWL+/PksWrSIe+65h7i4OA4cOMCYMWO4+uqrG73e87PPPktUVBTr169nzZo1DB8+vG7Zb3/7WxITE6murubyyy9nzZo13HPPPTz++OPk5uaedt2HlStXMmfOHJYvX46qMnr0aC699FISEhJ8nla8zaiphkPbnCJQe9u/Dg7vONUmPBZSB8CF3z1VCFKybFzAtAvtp0AEyLBhw9i/fz979uyhuLiYhIQEunTpwn333cfHH39Mhw4d2L17N/v27aNLly5eX+Pjjz/mnnvuAWDw4MEMHjy4btn8+fN5/vnnqaqqoqioiIKCgnrLG/r000/5zne+Uzer7HXXXccnn3zC1Vdf7fO04q1S6YHTC8H+DaeOGJIOkNQHug6DoTe7u4cGOuMFNkWEaafaT4E4yy/9k348nPT666/nzTffZO/evUyePJnXXnuN4uJiVq5cSVhYGBkZGV6n+T6b7du389hjj5Gfn09CQgLTp08/p9ep5eu04sFMaiqhaI1bCNa6u4fWQcm+U42iOzsb/5G3nxor6Nyv3rz/xpj2VCACaPLkydxxxx0cOHCAjz76iPnz55OSkkJYWBi5ubl8/fXXZ1z/kksuYe7cuVx22WWsXbuWNWvWAHDs2DGio6OJj49n3759vPfee3UDobXTjDfcxXTxxRczffp0HnjgAVSVt99+m1deecUvf7dfqTrnDDQoBJcUb4KPa5w2IRGQ0h/6TPAYNB4IMSmBzW5MK2EFogUMHDiQ48eP061bN9LS0rjpppv49re/zaBBg8jOzqZ///5nXP+HP/wht912G1lZWWRlZTFixAgAhgwZwrBhw+jfvz/p6emMG3dqvH/mzJlMnDiRrl27kpubW/f88OHDmT59OqNGjQKcQephw4YF9+6ksmNeBo0LoNxj0LhTD0i9kJ0dB9Fz1DedsYLEXnbdAGPOg9+m2mhp2dnZumLFinrPrV+/nqysLJ/WD8YzliE4c61fv559+/Y1/2Gb1VXuoHGDo4eO7DzVJiLO6QV4HkaakgWRzpRe7e1M1/NluZqmLeYSkaCdasO0VyXFpxeC/RugutxZLiGQ3Be6j4ThtzqFIHWAc3ipDRob0yKsQBj/qiyD4g31jx7atw5Ki0+1iUl1egOj7nALwUBIvgDCIgOX2xjT9guEqjZ6foFpukZ3Sao6u4IaFoKDW0DdQePQyFPzDaUMPDVoHJ3s/TWNMQHVpgtEZGQkBw8eJCkpyYpEM1BVDh48SGRYCPFHCuDzzacOI91XABUe04IkZDi9gQHXnhorSMysd91hY0xwa9MFonv37hQWFlJcXHzWtmVlZURGBt8ujYDlqqmBmkpnnqHaW3UlkUe30j3/12RWHIHVQGS8s/EfMsVj0Lg/RATXwLoxpunadIEICwsjMzPTp7Z5eXkMGzbMz4mazm+5VJ1xgEPbvN885x1CnMHhxEzn0NFLf8KavZUMnjDFuVKZ9c6MaZPadIFo92pqoGRvI0VgO1SUnGorIc65BIm9YFC282/tLaEnhEbUe+lDeXnOVNXGmDbLCkRrV1PtTEPdcONf+6/n1ck6hDkb+8Re0HNc/SLQqYfNRGqMqccKRGtQXeVcltJbT+DwDqiuONU2JOLUrqDel526n9gL4rrbmcXGGJ/Z1iJYVFU4h4k2KACjdq+Dj/fXv0xlWJSzwe/cz7kegWdPILYrdOgQuL/DGNNmWIFoSZVlzi9+bz2Bo7tOnS8AznUIknpREpNJVPaN9YtATKoNDBtj/M4KRHOrKPUYA2gwLnBsN86VVV2R8ZDY25lOYsiU+kUgKglEKMjLIyUI534xxrR9ViDORdkxOLwdDm5tMCi8zTlqyFNUsrPBz/hG/QKQmAlRiYHJb4wxPrAC0ZiTh0/f+NfeShuceBfTxdno95lQf1A4MdPpJRhjTCvk1wIhIhOB3wMhwCxVfbTB8h7Ay0Ant80DqrpQRK4AHgXCgQrgP1T1Q7+ELC+BDe+Ssf1DOPjqqSJw8nD9dnHdnQ1+v282OEcgAyJi/BLNGGMCyW8FQkRCgGeAK4BCIF9EFqhqgUezXwDzVfVZERkALAQygAPAt1V1j4hcCCwCuvklaHUFvP19etIBOqU7G/2B151+ophdjtIY0874swcxCtiiqtsARGQecA3gWSAUiHPvxwN7AFR1lUebdUBHEYlQ1fJmTxmVCHet4OM1O7j0siua/eWNMaa18tsV5URkEjBRVWe4j6cBo1X1Lo82acAHQAIQDUxQ1ZVeXucHqjrBy3vMBGYCpKamjpg3b9455y0pKSEmJvh2FVmuprFcTWO5mqYt5ho/fnyjV5RDVf1yAybhjDvUPp4GPN2gzU+An7r3x+L0Ljp4LB8IbAV6n+39RowYoecjNzf3vNb3F8vVNJaraSxX07TFXMAKbWS76s9TbncD6R6Pu7vPebodmA+gqkuBSCAZQES6A28Dt6jqVj/mNMaYVqn4eDkfbSpm9f6qszc+B/4cg8gH+opIJk5hmAJMbdBmJ3A58JKIZOEUiGIR6QT8A+eopn/5MaMxxgS9quoadhwsZd2eYxQUHWN90XEK9hzjQIkzLJse24F7/fC+fisQqlolInfhHIEUAsxW1XUi8ghOl2YB8FPgBRG5D2fAerqqqrteH+BBEXnQfcl/U9X9/sprjDHBoKS8ig1FTiEo2HOM9UXH2LD3OOVVzlQ8YSFC35RYLr2gMwO6xpGVFsuhrV/5JYtfz4NQ1YU4h656Pvegx/0CYJyX9X4D/Maf2YwxJpBUlT1Hy1i/x6MY7D3G1wdP1LXpFBXGgLQ4bh7TkwFpcQzoGkfvzjGEh9YfHcjb5Z+52exMamOM8bOKqho27z/u9giOU1B0lPVFxzl6srKuTUZSFAO7xjFpeHcGdHWKQZe4SCSAE3NagTDGmGZ0uLSC9bW7iNyewdbiEiqrnVMKIsM60K9LHN8clOYUgrRY+nWJIyYi+DbHwZfIGGNagZoa5etDJ5xi4I4VFBQdo+hoWV2blNgIBnSNY3z/FAakxZGVFkdmcjQhHVrHdP1WIIwx5ixOVlSzYe8x8nZVsuRvX7G+6Dgbio5RWlENQEgHoXfnaEZnJpLljhVkpcWRHBNxllcOblYgjDHGpaoUHy9nXdGxej2D7QdKqXEnnYiN2ENWWhzXZ6eTlRbLgLR4+qbGEBkWEtjwfmAFwhjTLlVV17DtQGm93UPri45xoOTUNd67J3QkKy2Obw3uSlZaHMd3FjDpyvEBHThuSVYgjDFt3rGySjYUHadgz1H3KKJjbNx3nAr33ILwkA5c0CWG8f1S6nYPZaXFEd8xrN7r5B3Y0G6KA1iBMMa0IapK4eGT9XoEBUXH2HXoZF2bxOhwBqTFcevYnnXFoHfnGMJC/DnzUOtkBcIY0yqVV1WzeV9J3aGktQXheJkzL5EIZCZFM7h7J6aM7FF3ollKbES76gWcDysQxpigd7CknPVFx0+dX+CeW1Dljhx3DAuhf1osVw/pWtcr6N8llqhw28SdD/v0jDFBpfDwCT4vqiJ/0Ya6nsG+Y6euFdYlLpKstFgmDEhhQFo8WWmx9ExqPecWtCZWIIwxAVVeVc3n2w+Rt7GYvI372VpcCkBoh230SYlhXO/keucWJEaHBzhx+2EFwhjT4nYdOkHexv3kbSzms60HOVlZTXhIB0b3SuTGUT0IPbSdG6/KISK07Z1b0JpYgTDG+F1ZpUcvYdN+trm9hPTEjkwa0Z2cfp0Z2zupbswgL2+nFYcgYAXCGOMXOw+eIG+T00tYWttLCO3A6MxEbhrdk5x+nemVHG1HFAUxKxDGmGZRVlnN8u2HyNu4n482FrPtgNNL6JEYxfXZTi9hTK8kO7KoFbH/UsaYc+bZS/hs6wHKKmsID+3AmF5J3DzG6SVkWi+h1bICYYzxWWO9hJ5JUUzOTienXwpjeiXRMdzGD9oCKxDGmDP6+mBp3SGoS7cdpKyyhgi3lzBtbE9y+qWQmRwd6JjGD/xaIERkIvB7IASYpaqPNljeA3gZ6OS2ecC9jjUi8nPgdqAauEdVF/kzqzHGUVZZzbJtB8nbWMxHm4rZ7vYSMpKimDKyB5f268yYTOsltAd+KxAiEgI8A1wBFAL5IrJAVQs8mv0CmK+qz4rIAGAhkOHenwIMBLoCS0TkAlWt9ldeY9qzHQdKnfMSNhWzzKOXMLZ3Ere6vYQM6yW0O/7sQYwCtqjqNgARmQdcA3gWCAXi3PvxwB73/jXAPFUtB7aLyBb39Zb6Ma8x7UZZZTVLtx3ktYJyHsrPZcfBEwBkJkczZWSPuiOO2uJFcIzvRFX988Iik4CJqjrDfTwNGK2qd3m0SQM+ABKAaGCCqq4UkaeBZar6qtvuReA9VX2zwXvMBGYCpKamjpg3b9455y0pKSEmJuac1/cXy9U0lqtxe0tr+Kq4mjUHqtlwqJrKGgjroGQlhTI4OYTBnUNIiQqOKa+D4fPypi3mGj9+/EpVzfa2LNCD1DcCL6nq/4nIWOAVEbnQ15VV9XngeYDs7GzNyck55yB5eXmcz/r+YrmaxnKdUttLyNvg7Dr6+qBzTYTM5GhuGtOZnH6dqShcx79dPr5Fc/nC/js2jb9y+bNA7AbSPR53d5/zdDswEUBVl4pIJJDs47rGmAa2144lbHTGEsqraogM68DYXkl8b1wmOf060zPp1FhCXlHBGV7NtHf+LBD5QF8RycTZuE8BpjZosxO4HHhJRLKASKAYWADMFZHHcQap+wKf+zGrMa3SyYraI45qewnOWEKv5Gimju5BTr8URmcm2liCOSd+KxCqWiUidwGLcA5hna2q60TkEWCFqi4Afgq8ICL34QxYT1dnUGSdiMzHGdCuAu60I5iMcS6p6fQSiuuOOKpwewkX9U7m9m9kknNBCj2SogId1bQBfh2DcM9pWNjguQc97hcA4xpZ97fAb/2Zz5jW4GRFNUu3HXBPVitm5yG3l9A5mpvdSe9GWS/B+EGgB6mNMQ2oKtsOnDp7efn2Q1RU1dAxLISLeidxx8WZ5PRLIT3RegnGv6xAGBMETlRUsXTrwbrrJew65Bxx1LtzNNPcSe9GZlgvwbQsKxDGBICqsrXYOeLoo03F9XoJ4/okMfOS3uRc0Nl6CSagrEAY00JOVFTx2ZaDddNjFx52egl9UmK4ZYwzncXIzAS7kpoJGj4VCBF5C6g9m7nGv5GMaTvKKqt5c2Uhr+efZPPixVRU1xAVHsJFvZP5waW9udR6CSaI+dqD+CNwG/CUiPwFmKOqG/0Xy5jWrbyqmvkrCnnmwy3sPVZG12jh1osyyOmXQnaG9RJM6+BTgVDVJTgzqsbjTI+xRER2AS8Ar6pqpR8zGtNqVFbX8ObKQp7+cAu7j5wku2cCj98whPJdXzF+/IBAxzOmSXwegxCRJOBmYBqwCngN+AZwK5Djj3DGtBZV1TW8tWo3f/hwM7sOnWRoeif+57pBXNw3GREhr9AuuWlaH1/HIN4G+gGvAN9W1SJ30RsissJf4YwJdtU1yoIvd/P7JZvZcfAEg7rF88j0C8np19muw2xaPV97EE+paq63BY1NE2tMW1ZTo7z7VRFPLtnEtuJSstLieOGWbCZkpVhhMG2GrwVigIisUtUjACKSANyoqn/0XzRjgk9NjfL+ur08uWQTm/aVcEFqDM/eNJx/H9iFDh2sMJi2xdcCcYeqPlP7QFUPi8gdOEc3GdPmqSofFOzjicWb2LD3OL07R/OHG4dx1aA0KwymzfK1QISIiLgzrdZebzrcf7GMCQ6qSu7G/Ty+eBNrdx8jMzmaJycP5dtDuhJihcG0cb4WiPdxBqSfcx9/333OmDZJVfl48wEeX7yJL3cdoUdiFI9dP4Rrh3YlNCQ4LstpjL/5WiDuxykKP3QfLwZm+SWRMQGkqny29SCPL97Eyq8P061TRx69bhDfHdGdMCsMpp3x9US5GuBZ92ZMm7Rsm1MYPt9+iLT4SH5z7YXckJ1OeKgVBtM++XoeRF/gf4ABOJcFBUBVe/kplzEtZsWOQzyxZBP/2nKQlNgIHr56IJNHptvU2qbd83UX0xzgV8ATwHiceZnsZ5Vp1VbtPMwTSzbz8aZikmPC+eW3BnDT6B5WGIxx+VogOqrqP90jmb4GHhKRlcCDZ1vRmGDzVeFRnliyiQ837CcxOpz/+mZ/bh7Tk6hwm/3eGE++fiPKRaQDsFlE7gJ2AzH+i2VM81u35yhPLtnM4oJ9xHcM4z/+vR/TL8ogOsIKgzHe+PrN+DEQBdwD/BpnN9OtZ1tJRCYCvwdCgFmq+miD5bW7rHBfP0VVO7nLfgdchbMrazHw49rzMIxpio17j/Pkkk28t3YvsZGh/OSKC7htXAaxkWGBjmZMUDtrgXBPipusqj8DSnDGH87KXe8Z4AqgEMgXkQWqWlDbRlXv82h/NzDMvX8RMA4Y7C7+FLgUyPPlvY0B2LK/hCeXbOIfXxURHR7KPZf35fZvZBLf0QqDMb44a4FQ1WoR+cY5vPYoYIuqbgMQkXnANUBBI+1vxBkIB1Cco6XCAQHCgH3nkMG0Q9sPlPLUPzfzzurdRIaF8MNLe3PHxb1IiLaT/41pCvFlr42IPAt0A/4ClNY+r6pvnWGdScBEVZ3hPp4GjFbVu7y07QksA7qrarX73GPADJwC8bSq/reX9WYCMwFSU1NHzJs376x/S2NKSkqIiQm+YRXL5bv9J2r464YT5BcLoQKX9wzjysww4sIDPyVGMH5eYLmaqi3mGj9+/MrGZuX2dQwiEjgIXObxnAKNFogmmgK86VEc+gBZQHd3+WIRuVhVP/FcSVWfB54HyM7O1pycnHMOkJeXx/ms7y+W6+wKD5/g6Q+38ObKQgThtnGZ/ODS3nSOjQh0tDrB9Hl5slxN095y+XomtU/jDg3sBtI9Hnd3n/NmCnCnx+PvAMtUtQRARN4DxgKfeFnXtFNFR0/yTO4W3sjfhSDcPKYnQ8L38Z2JdmlPY5qDr2dSz8HpMdSjqt87w2r5QF8RycQpDFOAqV5euz+QACz1eHoncIeI/A/OLqZLgSd9yWravn3Hyng2bytzl+9EUSaPTOdHOX3o2qkjeXnFgY5nTJvh6y6mdz3uR+L8wt9zphVUtco9Z2IRzmGus1V1nYg8AqxQ1QVu0ynAvAaHsL6JszvrK5zC9L6q/t3HrKaNKj5ezp8+2sqry76mqka5fkR37hzfh/TEqEBHM6ZN8nUX0189H4vI6ziHnp5tvYXAwgbPPdjg8UNe1qvGmT3WGA6WlPP8x9t4eekOKqpquG54d+6+rA89k6IDHc2YNu1cTyHtC6Q0ZxBjGjpcWsELn2zjpc92cLKymmuHduPuy/rQq3PwHUViTFvk6xjEceqPQezFuUaEMc3u6MlKXvx0O7M/3U5pRRVXDUrj3gl96ZMSG+hoxrQrvu5ism+m8bvjZZXM+dcOXvhkG8fLqrjywi78eO5DDIwAABWwSURBVEJf+neJC3Q0Y9olX3sQ3wE+VNWj7uNOQI6q/s2f4Uz7UFpexUufOYXhyIlKrhiQyr0T+jKwa3ygoxnTrvk6BvErVX279oGqHhGRXwFWIMw5O1lRzZ+X7uC5j7dxqLSCy/qncN+ECxjU3QqDMcHA1wLh7eJANkeyOSdlldW8tnwnz+Zt5UBJOZdc0Jn7JvRlWI+EQEczxnjwdSO/QkQex5mdFZyznlf6J5Jpq8oqq3kjfxfP5G5h//FyxvVJ4k8ThpOdkRjoaMYYL3wtEHcDvwTewDmaaTH1p8YwplEVVTXMX+EUhqKjZYzKSOSpG4cxpldSoKMZY87A16OYSoEH/JzFtDGV1TX8dWUhf/hwC7uPnGR4j048dv0QLuqdhEjgZ1g1xpyZr0cxLQauV9Uj7uMEnOkx/t2f4UzrVFVdw99W7+Gpf25m56ETDEnvxP+7bhCX9E22wmBMK+LrLqbk2uIAoKqHRcTOpDb1VNcof/9yD7//52a2Hyjlwm5xzJ6ezfh+KVYYjGmFfC0QNSLSQ1V3AohIBl5mdzXtU02N8o+vinhyySa2FpfSv0ssz00bwb8NSLXCYEwr5muB+G/gUxH5CGf67Ytxr+Rm2q+aGmXRur08uWQzG/cdp29KDH+8aTgTB3ahQwcrDMa0dr4OUr8vItk4RWEVzglyJ/0ZzAQvVeWLfVX87x8+ZX3RMXp1juapG4dx1aA0QqwwGNNm+DpIPQP4Mc5V4VYDY3Au8HPZmdYzbc+RExXc/vIKVn5dTkZSCE9MHsLVQ7pZYTCmDfJ1F9OPgZE4lwEd714F7v/5L5YJRsfKKrll9uds2Huc6QPD+cXUSwkN8XaSvTGmLfC1QJSpapmIICIRqrpBRPr5NZkJKqXlVdw2J5+CPcd4btoIQvatt+JgTBvn6ze80J3B9W/AYhF5B/jaf7FMMCmrrGbGyytYtfMwf7hxGJdnpQY6kjGmBfg6SP0d9+5DIpILxAPv+y2VCRrlVdV8/5WVLNt+kCduGMqVg9ICHckY00KavI9AVT9S1QWqWnG2tiIyUUQ2isgWETltqg4ReUJEVru3TSJyxGNZDxH5QETWi0iBe+6FaUGV1TXcNXcVH20q5tHrBnHtsG6BjmSMaUF+m7JbREJwZn+9AigE8kVkgaoW1LZR1fs82t8NDPN4iT8Dv1XVxSISA9T4K6s5XXWNct8bq1lcsI+Hrx7I5JE9Ah3JGNPC/DnKOArYoqrb3N7GPOCaM7S/EXgdQEQGAKGquhhAVUtU9YQfsxoPNTXKf765hnfXFPHzK/tz60UZgY5kjAkAUfXPjBkiMgmYqKoz3MfTgNGqepeXtj2BZUB3Va0WkWuBGUAFkAksAR5Q1eoG683EPaM7NTV1xLx58845b0lJCTExMee8vr+0dC5V5c8FFeTuquLaPmFc2yc8KHL5ynI1jeVqmraYa/z48StVNdvrQlX1yw2YBMzyeDwNeLqRtvcDf2iw7lGgF85usL8Ct5/p/UaMGKHnIzc397zW95eWzFVTU6OP/H2d9rz/Xf2fheu1pqYmKHI1heVqGsvVNG0xF7BCG9mu+nMX024g3eNxd/c5b6bg7l5yFQKr1dk9VYVzeO1wv6Q0df7vg028+Ol2pl+Uwf0T+9lEe8a0c/4sEPlAXxHJFJFwnCKwoGEj96zsBJypOzzX7SQind3HlwEFDdc1zefpDzfzdO4WbhyVzq++PcCKgzHGfwXC/eV/F7AIWA/MV9V1IvKIiFzt0XQKzsWH1GPdauBnwD9F5CucGWRf8FfW9m7WJ9t47INNXDesG7+9dpAVB2MM4MfDXAFUdSGwsMFzDzZ4/FAj6y4GBvstnAHglWVf85t/rOeqQWn8btJgm6bbGFPHJtNpx+av2MUv/7aWCVkpPDF5qM2tZIypx7YI7dQ7q3dz/1/XcHHfZJ6eOpzwUPtfwRhTn20V2qH31+7lJ/O/ZFRGIs9PyyYyLCTQkYwxQcgKRDuTu3E/d7/+BYO7x/Pi9JF0DLfiYIzxzgpEO/LZlgP84JWV9OsSy0u3jSImwq/HKBhjWjkrEO3Eih2HuP3lFWQkRfPK90YT3zEs0JGMMUHOCkQ78OWuI0yfk09afCSvzhhNQrT3+ZWMMcaTFYg2rmDPMW6Z/TkJ0WG8dsdoOsdGBDqSMaaVsALRhm3ed5ybX1xOVHgIc2eMIS2+Y6AjGWNaESsQbdSOA6XcNGs5IR2EuXeMIT0xKtCRjDGtjBWINqjw8AmmvrCMqhpl7ozRZCZHBzqSMaYVsgLRxuw9WsbUF5ZTUl7FK7ePom9qbKAjGWNaKTsQvg0pPl7O1FnLOFRawaszRjOwa3ygIxljWjHrQbQRh0srmPbicoqOlDF7+kiGpncKdCRjTCtnPYg24FhZJbfM/pxtB0qZM30kozITAx3JGNMGWA+ilSstr+K2Ofls2HuM524ewbg+yYGOZIxpI6wH0YqdrKjm9pfzWb3rCM9MHcb4/imBjmSMaUOsB9FKlVdV8/1XV7J8+yEev2EIEy9MC3QkY0wbYwWiFaqsruGuuav4eFMx/3vdYK4Z2i3QkYwxbZAViFamuka5943VLC7YxyPXDOSGkemBjmSMaaP8WiBEZKKIbBSRLSLygJflT4jIave2SUSONFgeJyKFIvK0P3O2FjU1yn+8+SX/WFPEf32zP7eMzQh0JGNMG+a3QWoRCQGeAa4ACoF8EVmgqgW1bVT1Po/2dwPDGrzMr4GP/ZWxNVFVfvHOWt76Yjc/ueICZl7SO9CRjDFtnD97EKOALaq6TVUrgHnANWdofyPweu0DERkBpAIf+DFjq6Cq/Prd9cxdvpMf5fTm7sv6BDqSMaYdEFX1zwuLTAImquoM9/E0YLSq3uWlbU9gGdBdVatFpAPwIXAzMAHIbmS9mcBMgNTU1BHz5s0757wlJSXExMSc8/r+UlJSwvt7wnl3WyVX9Axlav9wRCTQsYL687JcvrNcTdMWc40fP36lqmZ7WxYs50FMAd5U1Wr38Y+AhapaeKaNoao+DzwPkJ2drTk5OeccIC8vj/NZ319+8uIHvLutkqmje/Dbay8MiuIAwft5Wa6msVxN095y+bNA7AY8D7Hp7j7nzRTgTo/HY4GLReRHQAwQLiIlqnraQHdb9sLH23hrcyXXDe/Gb64JnuJgjGkf/Fkg8oG+IpKJUximAFMbNhKR/kACsLT2OVW9yWP5dJxdTO2qOLyydAe/XbieUV1C+N13B9OhgxUHY0zL8tsgtapWAXcBi4D1wHxVXScij4jI1R5NpwDz1F+DIa3Q/Pxd/PKddUzISmXm4AhCQ+x0FWNMy/PrGISqLgQWNnjuwQaPHzrLa7wEvNTM0YLWO6t3c/9ba7jkgs48c9Mwln76SaAjGWPaKftpGkTeX1vET+Z/yejMRJ67eQQRoSGBjmSMacesQASJ3A37ufv1VQzpHs+Lt46kY7gVB2NMYFmBCAL/2nKA77+6kv5d4njpe6OIjgiWo4+NMe2ZFYgAy99xiBkvr6BXcjR//t4o4iLDAh3JGGMAKxABtXrXEW6bk09ap0heuX00CdHhgY5kjDF1rEAEyLo9R7nlxeUkRoczd8YYOsdGBDqSMcbUYwUiADbvO860Fz8nJiKUuXeMpkt8ZKAjGWPMaaxAtLDtB0qZOms5oR2EuXeMoXtCVKAjGWOMV3a4TAvadegEN72wjOoa5Y2ZY8hIjg50JGOMaZT1IFrI3qNl3DRrOSXlVbx6+2j6psYGOpIxxpyR9SBaQPHxcqbOWsah0gpemzGaAV3jAh3JGGPOynoQfna4tIJpLy6n6EgZc24byZD0ToGOZIwxPrEehB8dPVnJtNnL2XaglDnTRzIyIzHQkYwxxmfWg/CTkvIqps/5nI17j/PctBGM65Mc6EjGGNMk1oPwg5MV1dz+Uj5rCo/yzNThjO+XEuhIxhjTZNaDaGblVdXMfGUFn+84xOM3DGHihV0CHckYY86JFYhmVFldw52vreKTzQf43+8O5pqh3QIdyRhjzpkViGZSVV3DvfNWs2T9Pn59zUBuyE4PdCRjjDkvViCaQU2N8p9vruEfXxXxi6uymDY2I9CRjDHmvPm1QIjIRBHZKCJbROQBL8ufEJHV7m2TiBxxnx8qIktFZJ2IrBGRyf7MeT5Ulf/+21reWrWbn15xATMu7hXoSMYY0yz8dhSTiIQAzwBXAIVAvogsUNWC2jaqep9H+7uBYe7DE8AtqrpZRLoCK0Vkkaoe8Vfec6GqPPJuAa9/vpM7x/fm7sv7BjqSMcY0G3/2IEYBW1R1m6pWAPOAa87Q/kbgdQBV3aSqm937e4D9QGc/Zm0yVeV3izYy5187uP0bmfzs3/oFOpIxxjQrfxaIbsAuj8eF7nOnEZGeQCbwoZdlo4BwYKsfMp6zP3y4hWfztnLT6B784qosRCTQkYwxplmJqvrnhUUmARNVdYb7eBowWlXv8tL2fqC7qt7d4Pk0IA+4VVWXeVlvJjATIDU1dcS8efPOOW9JSQkxMTE+tX1veyVvbKxgXNdQbh8UTgc/Foem5GpJlqtpLFfTWK6mOZ9c48ePX6mq2V4XqqpfbsBYYJHH458DP2+k7SrgogbPxQFfAJN8eb8RI0bo+cjNzfWp3cufbdee97+rd762Uquqa87rPX3ha66WZrmaxnI1jeVqmvPJBazQRrar/tzFlA/0FZFMEQkHpgALGjYSkf5AArDU47lw4G3gz6r6ph8zNskb+Tt58J11XDEglScmDyWkg+1WMsa0XX4rEKpaBdwFLALWA/NVdZ2IPCIiV3s0nQLMcytZrRuAS4DpHofBDvVXVl+8s3o3D7z1FZde0Jmnpw4jLMROITHGtG1+naxPVRcCCxs892CDxw95We9V4FV/ZmuK974q4ifzv2RMZhLPTRtBRGhIoCMZY4zf2c/gs/hwwz7umbeKoemdmHVrNpFhVhyMMe2DFYgz+HTzAX7w6hdkpcUx57aRREfY7OjGmPbDCkQjPt9+iBl/zqdXcjR//t4o4iLDAh3JGGNalBUIL1btPMxtcz6nW6eOvDpjNJ2iwgMdyRhjWpwViAbW7j7KrbM/Jzk2grl3jCE5JiLQkYwxJiCsQHjYtO84t8z+nNjIMF6bMZrUuMhARzLGmICxAuHaW1rDTbOWE9pBeG3GaLonRAU6kjHGBJQVCGDXoRP8Lr+Mmhpl7h2jyUiODnQkY4wJuHZ/3Obeo2VMnbWM8mrlLzNH0yclNtCRjDEmKLT7AhEdEcIFKbF8o58yoGtcoOMYY0zQaPe7mGIjw3hx+kgy4+0MaWOM8dTuC4QxxhjvrEAYY4zxygqEMcYYr6xAGGOM8coKhDHGGK+sQBhjjPHKCoQxxhivrEAYY4zxSlQ10BmahYgUA1+fx0skAweaKU5zslxNY7maxnI1TVvM1VNVO3tb0GYKxPkSkRWqmh3oHA1ZrqaxXE1juZqmveWyXUzGGGO8sgJhjDHGKysQpzwf6ACNsFxNY7maxnI1TbvKZWMQxhhjvLIehDHGGK+sQBhjjPGqXRUIEZkoIhtFZIuIPOBleYSIvOEuXy4iGUGSa7qIFIvIavc2o4VyzRaR/SKytpHlIiJPubnXiMjwIMmVIyJHPT6vB1soV7qI5IpIgYisE5Efe2nT4p+Zj7la/DMTkUgR+VxEvnRzPeylTYt/J33MFZDvpPveISKySkTe9bKseT8vVW0XNyAE2Ar0AsKBL4EBDdr8CPiTe38K8EaQ5JoOPB2Az+wSYDiwtpHl3wTeAwQYAywPklw5wLsB+LzSgOHu/Vhgk5f/li3+mfmYq8U/M/cziHHvhwHLgTEN2gTiO+lLroB8J933/gkw19t/r+b+vNpTD2IUsEVVt6lqBTAPuKZBm2uAl937bwKXi4gEQa6AUNWPgUNnaHIN8Gd1LAM6iUhaEOQKCFUtUtUv3PvHgfVAtwbNWvwz8zFXi3M/gxL3YZh7a3jUTIt/J33MFRAi0h24CpjVSJNm/bzaU4HoBuzyeFzI6V+SujaqWgUcBZKCIBfAd91dEm+KSLqfM/nK1+yBMNbdRfCeiAxs6Td3u/bDcH59egroZ3aGXBCAz8zdXbIa2A8sVtVGP68W/E76kgsC8518EvhPoKaR5c36ebWnAtGa/R3IUNXBwGJO/UIw3n2BM7/MEOAPwN9a8s1FJAb4K3Cvqh5ryfc+k7PkCshnpqrVqjoU6A6MEpELW+J9z8aHXC3+nRSRbwH7VXWlv9+rVnsqELsBzyrf3X3OaxsRCQXigYOBzqWqB1W13H04Cxjh50y+8uUzbXGqeqx2F4GqLgTCRCS5Jd5bRMJwNsKvqepbXpoE5DM7W65Afmbuex4BcoGJDRYF4jt51lwB+k6OA64WkR04u6IvE5FXG7Rp1s+rPRWIfKCviGSKSDjOAM6CBm0WALe69ycBH6o72hPIXA32UV+Nsw85GCwAbnGPzBkDHFXVokCHEpEutftdRWQUzv/nft+ouO/5IrBeVR9vpFmLf2a+5ArEZyYinUWkk3u/I3AFsKFBsxb/TvqSKxDfSVX9uap2V9UMnO3Eh6p6c4Nmzfp5hZ7riq2NqlaJyF3AIpwjh2ar6joReQRYoaoLcL5Er4jIFpxB0ClBkuseEbkaqHJzTfd3LgAReR3n6JZkESkEfoUzYIeq/glYiHNUzhbgBHBbkOSaBPxQRKqAk8CUFij04PzCmwZ85e6/BvgvoIdHtkB8Zr7kCsRnlga8LCIhOAVpvqq+G+jvpI+5AvKd9Mafn5dNtWGMMcar9rSLyRhjTBNYgTDGGOOVFQhjjDFeWYEwxhjjlRUIY4wxXlmBMCYIiDOb6mmzcxoTSFYgjDHGeGUFwpgmEJGb3WsFrBaR59xJ3UpE5An32gH/FJHObtuhIrLMndDtbRFJcJ/vIyJL3InxvhCR3u7Lx7gTv20QkddaYCZhY87ICoQxPhKRLGAyMM6dyK0auAmIxjmTdSDwEc6Z3QB/Bu53J3T7yuP514Bn3InxLgJqp9oYBtwLDMC5Psg4v/9RxpxBu5lqw5hmcDnOpGz57o/7jjjTQdcAb7htXgXeEpF4oJOqfuQ+/zLwFxGJBbqp6tsAqloG4L7e56pa6D5eDWQAn/r/zzLGOysQxvhOgJdV9ef1nhT5ZYN25zp/TbnH/Wrs+2kCzHYxGeO7fwKTRCQFQEQSRaQnzvdokttmKvCpqh4FDovIxe7z04CP3Cu6FYrIte5rRIhIVIv+Fcb4yH6hGOMjVS0QkV8AH4hIB6ASuBMoxbmozC9wdjlNdle5FfiTWwC2cWrm1mnAc+4snJXA9S34ZxjjM5vN1ZjzJCIlqhoT6BzGNDfbxWSMMcYr60EYY4zxynoQxhhjvLICYYwxxisrEMYYY7yyAmGMMcYrKxDGGGO8+v/u/+e4h1nThQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}